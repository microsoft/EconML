{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"0\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://ictd2016.files.wordpress.com/2016/04/microsoft-research-logo-copy.jpg\" style=\"width 30px;\" />\n",
    "             </td>\n",
    "        <td>\n",
    "            <img src=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/MSR-ALICE-HeaderGraphic-1920x720_1-800x550.jpg\" style=\"width 100px;\"/></td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection for Causal Effect Model with the RScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main imports\n",
    "from econml.dml import DML, LinearDML, SparseLinearDML, NonParamDML\n",
    "from econml.metalearners import XLearner, TLearner, SLearner, DomainAdaptationLearner\n",
    "from econml.drlearner import DRLearner\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example Usage with Single Binary Treatment Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. DGP \n",
    "We use the following DGP:\n",
    "\n",
    "\\begin{align}\n",
    "T \\sim & \\text{Bernoulli}\\left(f(W)\\right), &\\; f(W)=\\sigma(\\langle W, \\beta\\rangle + \\eta), \\;\\eta \\sim \\text{Uniform}(-1, 1)\\\\\n",
    "Y = & T\\cdot \\theta(X) + \\langle W, \\gamma\\rangle + \\epsilon, & \\; \\epsilon \\sim \\text{Uniform}(-1, 1)\\\\\n",
    "W \\sim & \\text{Normal}(0,\\, I_{n_w}) & \\\\\n",
    "X \\sim & \\text{Uniform}(0,\\, 1)^{n_x}\n",
    "\\end{align}\n",
    "\n",
    "where $W$ is a matrix of high-dimensional confounders, $\\beta, \\gamma$ have high sparsity and $\\sigma$ is the sigmoid function.\n",
    "\n",
    "For this DGP, \n",
    "\\begin{align}\n",
    "\\theta(x) = \\exp( 2\\cdot x_1 ).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment effect function\n",
    "def exp_te(x):\n",
    "    return np.exp(2 * x[:, 0]) # DGP constants\n",
    "# def exp_te(x):\n",
    "#     return 4*x[:, 0]\n",
    "def exp_te(x):\n",
    "    return x[:, 0] > 0.5\n",
    "# def exp_te(x):\n",
    "#     return (1 + x[:, 0]**2) * (x[:, 0] > .5)\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 5000\n",
    "support_size = 5\n",
    "n_x = 10\n",
    "# Outcome support\n",
    "support_Y = np.random.choice(range(n_x), size=support_size, replace=False)\n",
    "coefs_Y = np.random.uniform(0, 1, size=support_size)\n",
    "epsilon_sample = lambda n:np.random.uniform(-1, 1, size=n)\n",
    "# Treatment support\n",
    "support_T = support_Y\n",
    "coefs_T = np.random.uniform(0, 1, size=support_size)\n",
    "eta_sample = lambda n: np.random.uniform(-1, 1, size=n) \n",
    "\n",
    "# Generate controls, covariates, treatments and outcomes\n",
    "X = np.random.uniform(0, 1, size=(n, n_x))\n",
    "# Heterogeneous treatment effects\n",
    "TE = exp_te(X)\n",
    "# Define treatment\n",
    "log_odds = np.dot(X[:, support_T], coefs_T) + eta_sample(n)\n",
    "T_sigmoid = 1/(1 + np.exp(-log_odds))\n",
    "T = np.array([np.random.binomial(1, p) for p in T_sigmoid])\n",
    "# Define the outcome\n",
    "Y = TE * T + np.dot(X[:, support_Y], coefs_Y) + epsilon_sample(n)\n",
    "\n",
    "# get testing data\n",
    "X_test = np.random.uniform(0, 1, size=(n, n_x))\n",
    "X_test[:, 0] = np.linspace(0, 1, n)\n",
    "expected_te_test = exp_te(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = lambda: RandomForestRegressor(min_samples_leaf=10)\n",
    "clf = lambda: RandomForestClassifier(min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, T_train, T_val, Y_train, Y_val = train_test_split(X, T, Y, test_size=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('ldml', LinearDML(model_y=reg(), model_t=clf(), discrete_treatment=True,\n",
    "                             linear_first_stages=False, n_splits=3)),\n",
    "#           ('sldml', SparseLinearDML(model_y=reg(), model_t=clf(), discrete_treatment=True,\n",
    "#                                     featurizer=PolynomialFeatures(degree=2, include_bias=False),\n",
    "#                                     linear_first_stages=False, n_splits=3)),\n",
    "          ('xlearner', XLearner(models=reg(), cate_models=reg(), propensity_model=clf())),\n",
    "          ('dalearner', DomainAdaptationLearner(models=reg(), final_models=reg(), propensity_model=clf())),\n",
    "          ('slearner', SLearner(overall_model=reg())),\n",
    "          ('tlearner', TLearner(models=reg())),\n",
    "          ('drlearner', DRLearner(model_propensity=clf(), model_regression=reg(),\n",
    "                                  model_final=reg(), n_splits=3)),\n",
    "          ('rlearner', NonParamDML(model_y=reg(), model_t=clf(), model_final=reg(),\n",
    "                                   discrete_treatment=True, n_splits=3)),\n",
    "          ('dml3dlasso', DML(model_y=reg(), model_t=clf(), model_final=LassoCV(), discrete_treatment=True,\n",
    "                             featurizer=PolynomialFeatures(degree=3),\n",
    "                             linear_first_stages=False, n_splits=3))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def fit_model(name, model):\n",
    "    return name, model.fit(Y_train, T_train, X=X_train)\n",
    "\n",
    "models = Parallel(n_jobs=-1, verbose=1)(delayed(fit_model)(name, mdl) for name, mdl in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.score import RScorer\n",
    "\n",
    "scorer = RScorer(model_y=reg(), model_t=clf(),\n",
    "                 discrete_treatment=True, n_splits=3, mc_iters=2)\n",
    "scorer.fit(Y_val, T_val, X=X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscore = [scorer.score(mdl) for _, mdl in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_te_val = exp_te(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpehe = [np.sqrt(np.mean((expected_te_val.flatten() - mdl.effect(X_val).flatten())**2)) for _, mdl in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rootpehe, rscore)\n",
    "plt.xlabel('rpehe')\n",
    "plt.ylabel('rscore')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "rows = int(np.ceil(len(models) / 3))\n",
    "for it, (name, mdl) in enumerate(models):\n",
    "    plt.subplot(rows, 3, it + 1)\n",
    "    plt.title('{}. RScore: {:.3f}, Root-PEHE: {:.3f}'.format(name, rscore[it], rootpehe[it]))\n",
    "    plt.plot(X_test[:, 0], mdl.effect(X_test), label='{}'.format(it))\n",
    "    plt.plot(X_test[:, 0], expected_te_test, 'b--', label='True effect')\n",
    "plt.ylabel('Treatment Effect')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl, score  = scorer.best_model([mdl for _, mdl in models])\n",
    "rootpehe_best = np.sqrt(np.mean((expected_te_val.flatten() - mdl.effect(X_val).flatten())**2))\n",
    "plt.figure()\n",
    "plt.title('RScore: {:.3f}, Root-PEHE: {:.3f}'.format(score, rootpehe_best))\n",
    "plt.plot(X_test[:, 0], mdl.effect(X_test), label='best')\n",
    "plt.plot(X_test[:, 0], expected_te_test, 'b--', label='True effect')\n",
    "plt.ylabel('Treatment Effect')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting an Ensemble based on Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl, score  = scorer.ensemble([mdl for _, mdl in models])\n",
    "rootpehe_ensemble = np.sqrt(np.mean((expected_te_val.flatten() - mdl.effect(X_val).flatten())**2))\n",
    "plt.figure()\n",
    "plt.title('RScore: {:.3f}, Root-PEHE: {:.3f}'.format(score, rootpehe_ensemble))\n",
    "plt.plot(X_test[:, 0], mdl.effect(X_test), label='{}'.format(it))\n",
    "plt.plot(X_test[:, 0], expected_te_test, 'b--', label='True effect')\n",
    "plt.ylabel('Treatment Effect')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = lambda: RandomForestRegressor(min_samples_leaf=10, random_state=123)\n",
    "clf = lambda: RandomForestClassifier(min_samples_leaf=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.data.dgps import ihdp_surface_B, ihdp_surface_A\n",
    "Y, T, X, expected_te = ihdp_surface_B(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, T_train, T_val,\\\n",
    "Y_train, Y_val, expected_te_train, expected_te_val = train_test_split(X, T, Y, expected_te, test_size=.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('ldml', LinearDML(model_y=reg(), model_t=clf(), discrete_treatment=True,\n",
    "                             linear_first_stages=False, n_splits=3)),\n",
    "#           ('sldml', SparseLinearDML(model_y=reg(), model_t=clf(), discrete_treatment=True,\n",
    "#                                     featurizer=PolynomialFeatures(degree=2, include_bias=False),\n",
    "#                                     linear_first_stages=False, n_splits=3)),\n",
    "          ('xlearner', XLearner(models=reg(), cate_models=reg(), propensity_model=clf())),\n",
    "          ('dalearner', DomainAdaptationLearner(models=reg(), final_models=reg(), propensity_model=clf())),\n",
    "          ('slearner', SLearner(overall_model=reg())),\n",
    "          ('tlearner', TLearner(models=reg())),\n",
    "          ('drlearner', DRLearner(model_propensity=clf(), model_regression=reg(),\n",
    "                                  model_final=reg(), n_splits=3)),\n",
    "          ('rlearner', NonParamDML(model_y=reg(), model_t=clf(), model_final=reg(),\n",
    "                                   discrete_treatment=True, n_splits=3)),\n",
    "          ('dml3dlasso', DML(model_y=reg(), model_t=clf(), model_final=LassoCV(), discrete_treatment=True,\n",
    "                             featurizer=PolynomialFeatures(degree=2, interaction_only=True, include_bias=False),\n",
    "                             linear_first_stages=False, n_splits=3))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def fit_model(name, model):\n",
    "    return name, model.fit(Y_train, T_train, X=X_train)\n",
    "\n",
    "models = Parallel(n_jobs=-1, verbose=1)(delayed(fit_model)(name, mdl) for name, mdl in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.score import RScorer\n",
    "\n",
    "scorer = RScorer(model_y=reg(), model_t=clf(),\n",
    "                 discrete_treatment=True, n_splits=3)\n",
    "scorer.fit(Y_val, T_val, X=X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscore = [scorer.score(mdl) for _, mdl in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpehe = [np.sqrt(np.mean((expected_te.flatten() - mdl.effect(X).flatten())**2)) for _, mdl in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rootpehe, rscore)\n",
    "plt.xlabel('rpehe')\n",
    "plt.ylabel('rscore')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl, score  = scorer.best_model([mdl for _, mdl in models])\n",
    "rootpehe_best = np.sqrt(np.mean((expected_te_val.flatten() - mdl.effect(X_val).flatten())**2))\n",
    "rootpehe_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl, score  = scorer.ensemble([mdl for _, mdl in models])\n",
    "rootpehe_ensemble = np.sqrt(np.mean((expected_te_val.flatten() - mdl.effect(X_val).flatten())**2))\n",
    "rootpehe_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of bias distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.violinplot([np.abs(mdl.effect(X).flatten() - expected_te) for _, mdl in models] + \n",
    "               [np.abs(mdl.effect(X).flatten() - expected_te)], showmeans=True)\n",
    "plt.ylabel(\"Bias distribution\")\n",
    "plt.xticks(np.arange(1, len(models) + 2), [name for name, _ in models] + ['best'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
